<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Tianyang Liu</title> <meta name="author" content="Tianyang Liu"> <meta name="description" content="Tianyang Liu's personal website. "> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link href="https://fonts.googleapis.com/css2?family=Crimson+Text:wght@300;400;450;500;600;700&amp;display=swap" rel="stylesheet"> <script src="https://code.iconify.design/iconify-icon/1.0.7/iconify-icon.min.js"></script> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&amp;display=swap" rel="stylesheet"> <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&amp;family=EB+Garamond:ital,wght@0,400..800;1,400..800&amp;display=swap" rel="stylesheet"> <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&amp;display=swap" rel="stylesheet"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://leolty.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <div id="background-animation" class="background-animation"> </div> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%74%69%6C%30%34%30@%75%63%73%64,%65%64%75" title="email"> <i class="fa-regular fa-envelope"></i> </a> <a href="https://scholar.google.com/citations?user=rJAeYdwAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-google"></i></a> <a href="https://www.semanticscholar.org/author/2115347044" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/leolty" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github-alt"></i></a> <a href="https://www.linkedin.com/in/tianyangliu-whu-ucsd" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin-in"></i></a> <a href="https://twitter.com/ltyleoii22" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> <a href="https://instagram.com/leoii22" title="Instagram" rel="external nofollow noopener" target="_blank"><i class="fab fa-instagram"></i></a> <a href="/assets/pdf/TianyangLiu_CV_April_2024.pdf" title="CV"><i class="fas fa-file-pdf"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Tianyang</span> Liu </h1> <p class="desc">Ph.D. Student at UC San Diego</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/me_no_bg-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/me_no_bg-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/me_no_bg-1400.webp"></source> <img src="/assets/img/me_no_bg.png?349d13bb30ec70bbff6216d137a4e7d2" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="me_no_bg.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> </div> </div> <div class="clearfix"> <p>I am a <strong>Ph.D. student</strong> (2024-) in Computer Science at <a href="https://ucsd.edu/" rel="external nofollow noopener" target="_blank">UC San Diego</a>, advised by Prof. <a href="https://cseweb.ucsd.edu/~jmcauley/" rel="external nofollow noopener" target="_blank">Julian McAuley</a>.</p> <p>My research focuses on <strong>Natural Language Processing (NLP)</strong>, and I am broadly interested in <strong>Large Language Models (LLMs)</strong>. Specifically, I explore areas such as <strong>reasoning</strong> (<a href="https://arxiv.org/abs/2404.05221" rel="external nofollow noopener" target="_blank">LLM Reasoners</a>), <strong>tool augmentation</strong> (<a href="https://arxiv.org/abs/2305.11554" rel="external nofollow noopener" target="_blank">ToolkenGPT</a>), and <strong>code generation</strong> (<a href="https://arxiv.org/abs/2306.03091" rel="external nofollow noopener" target="_blank">RepoBench</a>, <a href="https://arxiv.org/abs/2402.19173" rel="external nofollow noopener" target="_blank">StarCoder2</a>). I am also interested in building <strong>code agents</strong>. Currently, I am deeply engaged in <strong>LLM evaluation</strong>, believing that <em>the future belongs to those who do evals</em>. <a href="https://x.com/TheGregYang/status/1839561802247799112" rel="external nofollow noopener" target="_blank">\(^‚Ä†\)</a></p> <p>Prior to my Ph.D. studies, I completed my Master‚Äôs degree in Computer Science at UC San Diego, working with Prof. <a href="https://cseweb.ucsd.edu/~jmcauley/" rel="external nofollow noopener" target="_blank">Julian McAuley</a> and Prof. <a href="http://zhiting.ucsd.edu/index.html" rel="external nofollow noopener" target="_blank">Zhiting Hu</a>. During this time, I also collaborated with Prof. <a href="https://muhaochen.github.io/" rel="external nofollow noopener" target="_blank">Muhao Chen</a> from UC Davis. Before that, I earned my Bachelor‚Äôs degree from <a href="https://en.whu.edu.cn/" rel="external nofollow noopener" target="_blank">Wuhan University</a>. I have also interned at <strong>NVIDIA</strong>, working with <a href="https://www.linkedin.com/in/gaoyan-xie-b2170517/" rel="external nofollow noopener" target="_blank">Gaoyan Xie</a> and his team on <strong>CUDA code agents</strong>.</p> <blockquote> <p>I am actively seeking undergraduate and master‚Äôs students interested in collaborating on research projects related to code generation, agents, benchmarking, reasoning, and similar topics. If you‚Äôre passionate about these areas, please don‚Äôt hesitate to email me.</p> </blockquote> </div> <h2><a href="/news/" style="color: inherit;">News</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Oct 10, 2024</th> <td> ü§ñ We pre-release <a href="https://de-arena.maitrix.org/" rel="external nofollow noopener" target="_blank">Decentralized Arena</a> for automated, scalable, and transparent LLM evaluation. </td> </tr> <tr> <th scope="row">Sep 20, 2024</th> <td> üéâ <a href="">DRPO</a> is accepted to the main conference of EMNLP 2024! </td> </tr> <tr> <th scope="row">Jul 10, 2024</th> <td> üéâ <a href="https://arxiv.org/abs/2404.05221" rel="external nofollow noopener" target="_blank">LLM Reasoners</a> is accepted to COLM 2024! </td> </tr> <tr> <th scope="row">Feb 28, 2024</th> <td> üí´ We release <a href="https://arxiv.org/abs/2402.19173" rel="external nofollow noopener" target="_blank">StarCoder 2</a>, a family of open LLMs for code. </td> </tr> <tr> <th scope="row">Jan 16, 2024</th> <td> üéâ <a href="https://arxiv.org/abs/2306.03091" rel="external nofollow noopener" target="_blank">RepoBench</a> gets accepted to ICLR 2024! </td> </tr> </table> </div> </div> <h2>Selected Publications <a href="/publications/" style="font-size: 1.4rem;">[view all]</a> </h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">pre-release</abbr></div> <div id="yin2024decentralized" class="col-sm-8"> <div class="title"><a href="https://de-arena.maitrix.org/" target="_blank" rel="external nofollow noopener"><b>Decentralized Arena via Collective LLM Intelligence: Building Automated, Robust, and Transparent LLM Evaluation for Numerous Dimensions</b></a></div> <div class="author"> Yanbin Yin,¬†<a href="https://zhenwang9102.github.io/" rel="external nofollow noopener" target="_blank">Zhen Wang</a>,¬†<a href="https://lancelot39.github.io/" rel="external nofollow noopener" target="_blank">Kun Zhou</a>,¬†Xiangdong Zhang,¬†<a href="https://ber666.github.io/" rel="external nofollow noopener" target="_blank">Shibo Hao</a>,¬†<a href="https://www.yigu.page/" rel="external nofollow noopener" target="_blank">Yi Gu</a>,¬†Jieyuan Liu,¬†Somanshu Singla,¬†<em>Tianyang Liu</em>,¬†<a href="https://www.cs.cmu.edu/~epxing/" rel="external nofollow noopener" target="_blank">Eric P. Xing</a>,¬†Zhengzhong Liu,¬†Haojian Jin, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Zhiting Hu' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '4'); ">1 more author</span> </div> <div class="periodical"> <em>Pre-release</em>, 2024 </div> <div class="periodical"> Final version will be released soon. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://de-arena.maitrix.org/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>We release Decentralized Arena that automates and scales ‚ÄúChatbot Arena‚Äù for LLM evaluation across various fine-grained dimensions (e.g., math ‚Äì algebra, geometry, probability; logical reasoning, social reasoning, biology, chemistry, ‚Ä¶). The evaluation is decentralized and democratic, with all LLMs participating in evaluating others. It achieves a 95% correlation with Chatbot Arena‚Äôs overall rankings, while being fully transparent and reproducible.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yin2024decentralized</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decentralized Arena via Collective LLM Intelligence: Building Automated, Robust, and Transparent LLM Evaluation for Numerous Dimensions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yin, Yanbin and Wang, Zhen and Zhou, Kun and Zhang, Xiangdong and Hao, Shibo and Gu, Yi and Liu, Jieyuan and Singla, Somanshu and Liu, Tianyang and Xing, Eric P. and Liu, Zhengzhong and Jin, Haojian and Hu, Zhiting}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Pre-release}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://de-arena.maitrix.org/}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Final version will be released soon.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">EMNLP (main)</abbr></div> <div id="singla2024dynamic" class="col-sm-8"> <div class="title"><b>Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models</b></div> <div class="author"> Somanshu Singla*,¬†<a href="https://zhenwang9102.github.io/" rel="external nofollow noopener" target="_blank">Zhen Wang*</a>,¬†<em>Tianyang Liu</em>,¬†Abdullah Ashfaq,¬†<a href="http://zhiting.ucsd.edu/index.html" rel="external nofollow noopener" target="_blank">Zhiting Hu</a>,¬†and¬†<a href="https://www.cs.cmu.edu/~epxing/" rel="external nofollow noopener" target="_blank">Eric P. Xing</a> </div> <div class="periodical"> <em>EMNLP</em>, 2024 </div> <div class="periodical"> The camera-ready paper and code will be made available soon. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Aligning Large Language Models (LLMs) traditionally relies on costly training processes like supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF). To enable alignment without these expensive tuning and annotation, we present a new tuning-free approach for self-alignment called Dynamic Rewarding with Prompt Optimization (DRPO). Our approach enables self-alignment through a search-based prompt optimization framework, allowing the model to self-improve and generate optimized prompts without additional training or human supervision. The core of DRPO leverages a dynamic rewarding mechanism to identify and rectify model-specific alignment weaknesses, enabling LLMs to adapt quickly to various alignment challenges. Empirical evaluations on eight recent LLMs, including both open- and closed-source, reveal that DRPO significantly enhances alignment performance, enabling base models to outperform their SFT/RLHF-tuned counterparts. Moreover, DRPO‚Äôs automatically optimized prompts surpass those curated by human experts, demonstrating its superior alignment capabilities. Our findings envision a highly cost-effective and adaptable solution for future alignment research to be further explored.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">singla2024dynamic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Singla*, Somanshu and Wang*, Zhen and Liu, Tianyang and Ashfaq, Abdullah and Hu, Zhiting and Xing, Eric P.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{EMNLP}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{The camera-ready paper and code will be made available soon.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">COLM</abbr></div> <div id="hao2024llm" class="col-sm-8"> <div class="title"><a href="http://arxiv.org/abs/2404.05221" target="_blank" rel="external nofollow noopener"><b>LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models</b></a></div> <div class="author"> <a href="https://ber666.github.io/" rel="external nofollow noopener" target="_blank">Shibo Hao</a>,¬†<a href="https://www.yigu.page/" rel="external nofollow noopener" target="_blank">Yi Gu</a>,¬†Haotian Luo,¬†<em>Tianyang Liu</em>,¬†Xiyan Shao,¬†Xinyuan Wang,¬†Shuhua Xie,¬†Haodi Ma,¬†Adithya Samavedhi,¬†Qiyue Gao,¬†<a href="https://zhenwang9102.github.io/" rel="external nofollow noopener" target="_blank">Zhen Wang</a>,¬†and¬†<a href="http://zhiting.ucsd.edu/index.html" rel="external nofollow noopener" target="_blank">Zhiting Hu</a> </div> <div class="periodical"> <em>COLM</em>, 2024 </div> <div class="periodical"> Also to appear at Large Language Model (LLM) Agents workshop at ICLR 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2404.05221" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/maitrix-org/llm-reasoners" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Generating accurate step-by-step reasoning is essential for Large Language Models (LLMs) to address complex problems and enhance robustness and interpretability. Despite the flux of research on developing advanced reasoning approaches, systematically analyzing the diverse LLMs and reasoning strategies in generating reasoning chains remains a significant challenge. The difficulties stem from the lack of two key elements: (1) an automatic method for evaluating the generated reasoning chains on different tasks, and (2) a unified formalism and implementation of the diverse reasoning approaches for systematic comparison. This paper aims to close the gap: (1) We introduce AutoRace for fully automated reasoning chain evaluation. Existing metrics rely on expensive human annotations or pre-defined LLM prompts not adaptable to different tasks. In contrast, AutoRace automatically creates detailed evaluation criteria tailored for each task, and uses GPT-4 for accurate evaluation following the criteria. (2) We develop LLM Reasoners, a library for standardized modular implementation of existing and new reasoning algorithms, under a unified formulation of the search, reward, and world model components. With the new evaluation and library, (3) we conduct extensive study of different reasoning approaches (e.g., CoT, ToT, RAP). The analysis reveals interesting findings about different factors contributing to reasoning, including the reward-guidance, breadth-vs-depth in search, world model, and prompt formats, etc.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hao2024llm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hao, Shibo and Gu, Yi and Luo, Haotian and Liu, Tianyang and Shao, Xiyan and Wang, Xinyuan and Xie, Shuhua and Ma, Haodi and Samavedhi, Adithya and Gao, Qiyue and Wang, Zhen and Hu, Zhiting}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{COLM}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Language Modeling}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Also to appear at Large Language Model (LLM) Agents workshop at ICLR 2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">preprint</abbr></div> <div id="starcoder2" class="col-sm-8"> <div class="title"><a href="http://arxiv.org/abs/2402.19173" target="_blank" rel="external nofollow noopener"><b>StarCoder 2 and The Stack v2: The Next Generation</b></a></div> <div class="author"> Anton Lozhkov,¬†Raymond Li,¬†Loubna Ben Allal,¬†Federico Cassano,¬†Joel Lamy-Poirier,¬†Nouamane Tazi,¬†Ao Tang,¬†Dmytro Pykhtar,¬†Jiawei Liu,¬†Yuxiang Wei,¬†<em>Tianyang Liu</em>,¬†Max Tian, and <span class="more-authors" title="click to view 54 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '54 more authors' ? 'Denis Kocetkov, Arthur Zucker, Younes Belkada, Zijian Wang, Qian Liu, Dmitry Abulkhanov, Indraneil Paul, Zhuang Li, Wen-Ding Li, Megan Risdal, Jia Li, Jian Zhu, Terry Yue Zhuo, Evgenii Zheltonozhskii, Nii Osae Osae Dade, Wenhao Yu, Lucas Krau√ü, Naman Jain, Yixuan Su, Xuanli He, Manan Dey, Edoardo Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang, Muhtasham Oblokulov, Christopher Akiki, Marc Marone, Chenghao Mou, Mayank Mishra, Alex Gu, Binyuan Hui, Tri Dao, Armel Zebaze, Olivier Dehaene, Nicolas Patry, Canwen Xu, Julian McAuley, Han Hu, Torsten Scholak, Sebastien Paquet, Jennifer Robinson, Carolyn Jane Anderson, Nicolas Chapados, Mostofa Patwary, Nima Tajbakhsh, Yacine Jernite, Carlos Mu√±oz Ferrandis, Lingming Zhang, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro Werra, Harm Vries' : '54 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '4'); ">54 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2402.19173" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://huggingface.co/blog/starcoder2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="https://github.com/bigcode-project/starcoder2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The BigCode project, an open-scientific collaboration focused on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder2. In partnership with Software Heritage (SWH), we build The Stack v2 on top of the digital commons of their source code archive. Alongside the SWH repositories spanning 619 programming languages, we carefully select other high-quality data sources, such as GitHub pull requests, Kaggle notebooks, and code documentation. This results in a training set that is 4x larger than the first StarCoder dataset. We train StarCoder2 models with 3B, 7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate them on a comprehensive set of Code LLM benchmarks. We find that our small model, StarCoder2-3B, outperforms other Code LLMs of similar size on most benchmarks, and also outperforms StarCoderBase-15B. Our large model, StarCoder2- 15B, significantly outperforms other models of comparable size. In addition, it matches or outperforms CodeLlama-34B, a model more than twice its size. Although DeepSeekCoder- 33B is the best-performing model at code completion for high-resource languages, we find that StarCoder2-15B outperforms it on math and code reasoning benchmarks, as well as several low-resource languages. We make the model weights available under an OpenRAIL license and ensure full transparency regarding the training data by releasing the SoftWare Heritage persistent IDentifiers (SWHIDs) of the source code data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">starcoder2</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{StarCoder 2 and The Stack v2: The Next Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lozhkov, Anton and Li, Raymond and Allal, Loubna Ben and Cassano, Federico and Lamy-Poirier, Joel and Tazi, Nouamane and Tang, Ao and Pykhtar, Dmytro and Liu, Jiawei and Wei, Yuxiang and Liu, Tianyang and Tian, Max and Kocetkov, Denis and Zucker, Arthur and Belkada, Younes and Wang, Zijian and Liu, Qian and Abulkhanov, Dmitry and Paul, Indraneil and Li, Zhuang and Li, Wen-Ding and Risdal, Megan and Li, Jia and Zhu, Jian and Zhuo, Terry Yue and Zheltonozhskii, Evgenii and Dade, Nii Osae Osae and Yu, Wenhao and Krau√ü, Lucas and Jain, Naman and Su, Yixuan and He, Xuanli and Dey, Manan and Abati, Edoardo and Chai, Yekun and Muennighoff, Niklas and Tang, Xiangru and Oblokulov, Muhtasham and Akiki, Christopher and Marone, Marc and Mou, Chenghao and Mishra, Mayank and Gu, Alex and Hui, Binyuan and Dao, Tri and Zebaze, Armel and Dehaene, Olivier and Patry, Nicolas and Xu, Canwen and McAuley, Julian and Hu, Han and Scholak, Torsten and Paquet, Sebastien and Robinson, Jennifer and Anderson, Carolyn Jane and Chapados, Nicolas and Patwary, Mostofa and Tajbakhsh, Nima and Jernite, Yacine and Ferrandis, Carlos Mu√±oz and Zhang, Lingming and Hughes, Sean and Wolf, Thomas and Guha, Arjun and von Werra, Leandro and de Vries, Harm}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NAACL</abbr></div> <div id="liu2023rethinking" class="col-sm-8"> <div class="title"><a href="http://arxiv.org/abs/2312.16702" target="_blank" rel="external nofollow noopener"><b>Rethinking Tabular Data Understanding of Large Language Models</b></a></div> <div class="author"> <em>Tianyang Liu</em>,¬†<a href="https://feiwang96.github.io/" rel="external nofollow noopener" target="_blank">Fei Wang</a>,¬†and¬†<a href="https://muhaochen.github.io/" rel="external nofollow noopener" target="_blank">Muhao Chen</a> </div> <div class="periodical"> <em>NAACL</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2312.16702" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/Leolty/tablellm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Large Language Models (LLMs) have shown to be capable of various tasks, yet their capability in interpreting and reasoning over tabular data remains an underexplored area. In this context, this study investigates from three core perspectives: the robustness of LLMs to structural perturbations in tables, the comparative analysis of textual and symbolic reasoning on tables, and the potential of boosting model performance through the aggregation of multiple reasoning pathways. We discover that structural variance of tables presenting the same content reveals a notable performance decline, particularly in symbolic reasoning tasks. This prompts the proposal of a method for table structure normalization. Moreover, textual reasoning slightly edges out symbolic reasoning, and a detailed error analysis reveals that each exhibits different strengths depending on the specific tasks. Notably, the aggregation of textual and symbolic reasoning pathways, bolstered by a mix self-consistency mechanism, resulted in achieving SOTA performance, with an accuracy of 73.6% on WIKITABLEQUESTIONS, representing a substantial advancement over previous existing table processing paradigms of LLMs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2023rethinking</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Rethinking Tabular Data Understanding of Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Tianyang and Wang, Fei and Chen, Muhao}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{NAACL}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Annual Conference of the North American Chapter of the Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div id="liu2023repobench" class="col-sm-8"> <div class="title"><a href="http://arxiv.org/abs/2306.03091" target="_blank" rel="external nofollow noopener"><b>RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems</b></a></div> <div class="author"> <em>Tianyang Liu</em>,¬†<a href="https://www.canwenxu.net/" rel="external nofollow noopener" target="_blank">Canwen Xu</a>,¬†and¬†<a href="https://cseweb.ucsd.edu/~jmcauley/" rel="external nofollow noopener" target="_blank">Julian McAuley</a> </div> <div class="periodical"> <em>ICLR</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.03091" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/leolty/RepoBench" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Large Language Models (LLMs) have greatly advanced code auto-completion systems, with a potential for substantial productivity enhancements for developers. However, current benchmarks mainly focus on single-file tasks, leaving an assessment gap for more complex, real-world, multi-file programming scenarios. To fill this gap, we introduce RepoBench, a new benchmark specifically designed for evaluating repository-level code auto-completion systems. RepoBench consists of three interconnected evaluation tasks: RepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P (Pipeline). Each task respectively measures the system‚Äôs ability to retrieve the most relevant code snippets from other files as cross-file context, predict the next line of code with cross-file and in-file context, and handle complex tasks that require a combination of both retrieval and next-line prediction. RepoBench aims to facilitate a more complete comparison of performance and encouraging continuous improvement in auto-completion systems. RepoBench is publicly available at https://github.com/leolty/RepoBench</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2023repobench</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Tianyang and Xu, Canwen and McAuley, Julian}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ICLR}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Twelfth International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="hao2023toolkengpt" class="col-sm-8"> <div class="title"><a href="http://arxiv.org/abs/2305.11554" target="_blank" rel="external nofollow noopener"><b>ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings</b></a></div> <div class="author"> <a href="https://ber666.github.io/" rel="external nofollow noopener" target="_blank">Shibo Hao</a>,¬†<em>Tianyang Liu</em>,¬†<a href="https://zhenwang9102.github.io/" rel="external nofollow noopener" target="_blank">Zhen Wang</a>,¬†and¬†<a href="http://zhiting.ucsd.edu/index.html" rel="external nofollow noopener" target="_blank">Zhiting Hu</a> </div> <div class="periodical"> <em>NeurIPS</em>, 2023 </div> <div class="periodical"> <strong style="color:#cc3333">Oral (67 out of 12345 submissions), Best Paper Award at SoCal NLP 2023</strong> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.11554" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/Ber666/ToolkenGPT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/toolkenGPT-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Augmenting large language models (LLMs) with external tools has emerged as a promising approach to solving complex problems. However, traditional methods, which finetune LLMs with tool demonstration data, can be both costly and restricted to a predefined set of tools. Recent in-context learning paradigm alleviates these issues, but the limited context length only allows for a few shots of demonstrations, leading to suboptimal understandings of the tools. Moreover, when there are numerous tools to choose from, in-context learning could completely fail to work. In this paper, we propose an alternative approach, <strong>ToolkenGPT</strong>, which combines the benefits of both sides. Our approach represents each <u>tool</u> as a <u>ken</u> (i.e., toolken) and learns an embedding for it, enabling tool calls in the same way as generating a regular word token. Once a toolken is triggered, the LLM is prompted to complete arguments for the tool to execute. ToolkenGPT offers the flexibility to plug in an arbitrary number of tools by expanding the set of toolkens on the fly. In addition, it improves tool use by allowing extensive demonstration data for learning the toolken embeddings. In diverse domains, including numerical reasoning, knowledge-based question answering, and embodied plan generation, our approach effectively augments LLMs with tools and substantially outperforms various latest baselines. ToolkenGPT demonstrates the promising ability to use relevant tools from a large tool set in complex scenarios.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hao2023toolkengpt</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hao, Shibo and Liu, Tianyang and Wang, Zhen and Hu, Zhiting}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{&lt;strong style="color:#cc3333"&gt;Oral (67 out of 12345 submissions), Best Paper Award at SoCal NLP 2023&lt;/strong&gt;}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <h2>Services</h2> <div class="services-section"> <div class="services-content"> <h3 class="services-role">Invited Reviewer</h3> <div class="services-timeline"> <div class="timeline-item"> <div class="year">2025</div> <ul> <li>AAAI</li> <li>ICLR</li> <li>AISTATS</li> </ul> </div> <div class="timeline-item"> <div class="year">2024</div> <ul> <li>NeurIPS</li> <li>COLM</li> <li>ICML</li> <li>ICLR</li> <li>ACL ARR (Feb, Apr, Jun, Aug, Oct)</li> </ul> </div> <div class="timeline-item"> <div class="year">2023</div> <ul> <li>ACL ARR (Dec)</li> <li>NLPCC</li> </ul> </div> </div> </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> ¬© Copyright 2024 Tianyang Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: October 15, 2024. </div> <div id="map-container" style="display: none;"> <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&amp;w=300&amp;t=n&amp;d=vcetvMKxQeU0A74GGVddvtKdDYpzY562Hjs3OBdOjBw"></script> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/live2d-widget@3.0.4/lib/L2Dwidget.min.js"></script> <style>#live2dcanvas{border:none!important}@media screen and (max-width:768px){#live2dcanvas{transform:scale(0.47)!important;transform-origin:bottom right!important}}</style> <script>var config={model:{jsonPath:"https://cdn.jsdelivr.net/gh/cc963020001/myproject@1.0/kmusume/2d-mao/hijiki.model.json"},display:{superSample:1.5,width:160,height:160,position:"right",hOffset:0,vOffset:0},mobile:{show:!0,scale:.25,motion:!0},react:{opacityDefault:1,opacityOnHover:.75}};L2Dwidget.init(config);</script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script src="/assets/js/custom-cursor.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>function getRandomEmojiFromRanges(){const e=fallbackRanges[Math.floor(Math.random()*fallbackRanges.length)];return String.fromCodePoint(Math.floor(Math.random()*(e[1]-e[0]+1))+e[0])}function setBackgroundDimensions(){const e=document.body.scrollHeight,o=document.body.scrollWidth,n=document.getElementById("background-animation");n.style.height=`${e}px`,n.style.width=`${o}px`}function calculateEmojiCount(){const e=document.body.scrollHeight*document.body.scrollWidth,o=1/110224;return Math.min(100,Math.max(20,Math.round(e*o)))}async function fetchEmojis(){try{const o=new AbortController,n=setTimeout(()=>o.abort(),FETCH_TIMEOUT),t=await fetch("https://emojihub.yurace.pro/api/all",{signal:o.signal});clearTimeout(n);const i=await t.json();allowedCategories.forEach(e=>{const o=i.filter(o=>o.category===e&&!bannedGroups.includes(o.group)),n=getRandomSelection([...new Set(o)],categoryQuotas[e]).map(e=>e.htmlCode[0]);allEmojis.push(...n)}),console.log("Fetched and filtered",allEmojis.length,"emojis from API"),unusedEmojis=[...allEmojis],emojisEnabled=!0,setBackgroundDimensions(),addEmojis(calculateEmojiCount())}catch(e){console.error("Error fetching emojis:",e),console.log("Disabling emoji background animation")}}function getRandomSelection(e,o){return e.sort(()=>.5-Math.random()).slice(0,o)}function getRandomEmoji(){0===unusedEmojis.length&&(unusedEmojis=[...allEmojis]);const e=Math.floor(Math.random()*unusedEmojis.length);return unusedEmojis.splice(e,1)[0]}function createRandomEmoji(){const e=document.createElement("span");return e.className="floating-icon",e.innerHTML=getRandomEmoji(),e}function addEmojis(e){const o=document.getElementById("background-animation"),n=document.body.scrollHeight,t=document.body.scrollWidth;for(let i=0;i<e;i++){const e=createRandomEmoji();e.style.top=`${Math.random()*n}px`,e.style.left=`${Math.random()*t}px`,o.appendChild(e)}}function clearEmojis(){document.getElementById("background-animation").innerHTML=""}function hasSignificantResize(){const e=Math.abs(window.innerWidth-previousWidth)/previousWidth,o=Math.abs(window.innerHeight-previousHeight)/previousHeight;return e>.2||o>.2}let allEmojis=[],unusedEmojis=[],previousWidth=window.innerWidth,previousHeight=window.innerHeight,emojisEnabled=!1;const FETCH_TIMEOUT=5e3,categoryQuotas={"smileys and people":30,"animals and nature":30,"food and drink":30,"travel and places":10,activities:10,objects:10},bannedGroups=["face-negative","face-role","face-sick","family","person","person-activity","person-role","skin-tone"],allowedCategories=Object.keys(categoryQuotas),fallbackRanges=[[128512,128591],[127792,127839],[129360,129388],[129408,129455],[128e3,128063]];window.addEventListener("resize",()=>{if(emojisEnabled&&hasSignificantResize()){previousWidth=window.innerWidth,previousHeight=window.innerHeight,clearEmojis(),setBackgroundDimensions(),addEmojis(calculateEmojiCount())}}),window.addEventListener("load",()=>{fetchEmojis()});</script> </body> </html>